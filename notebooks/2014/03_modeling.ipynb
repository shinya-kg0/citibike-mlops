{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b0328d",
   "metadata": {},
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«èª¿æŸ»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a889a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb9835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.utils.io import load_month_data\n",
    "from src.utils.preprocess import preprocess_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717d44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_experiment(\n",
    "    data_info: list[int],\n",
    "    model_name: str = \"logistic_regression\",\n",
    "    params: dict | None = None,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "    experiment_name: str = \"citibike_membership\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    å­¦ç¿’ã¨MLflowã¸ã®ãƒ­ã‚°ã‚’è¡Œã†æ±Žç”¨é–¢æ•°\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_info :list[int]\n",
    "        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆCSVï¼‰å–å¾—ã«å¿…è¦ãªæƒ…å ± (exï¼‰[2014, 1])\n",
    "    model_name : str\n",
    "        ãƒ¢ãƒ‡ãƒ«åï¼ˆMLflowã®run_nameãªã©ã«ä½¿ç”¨ï¼‰\n",
    "    params : dict\n",
    "        ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    test_size : float\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ¯”çŽ‡\n",
    "    random_state : int\n",
    "        ä¹±æ•°ã‚·ãƒ¼ãƒ‰\n",
    "    experiment_name : str\n",
    "        MLflowå®Ÿé¨“å\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : å®Ÿé¨“çµæžœã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading data from {data_info[0]}-{data_info[1]}\")\n",
    "\n",
    "        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "        df_org = load_month_data(*data_info)\n",
    "        df = preprocess_pipeline(df_org)\n",
    "        \n",
    "        X = df.drop(\"is_member\", axis=1)\n",
    "        y = df[\"is_member\"]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Data split: train={len(X_train)}, test={len(X_test)}\")\n",
    "\n",
    "        if params is None:\n",
    "            params = {\"max_iter\": 500, \"random_state\": random_state}\n",
    "\n",
    "        if model_name == \"logistic_regression\":\n",
    "            model = LogisticRegression(**params)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "        # MLflowè¨­å®š\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "        with mlflow.start_run(\n",
    "            run_name=f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        ) as run:\n",
    "            logger.info(f\"MLflow run started: {run.info.run_id}\")\n",
    "            \n",
    "            dataset_params = {\n",
    "                \"data_info\": data_info,\n",
    "                \"test_size\": test_size,\n",
    "                \"random_state\": random_state,\n",
    "                \"train_samples\": len(X_train),\n",
    "                \"test_samples\": len(X_test),\n",
    "                \"n_features\": X_train.shape[1],\n",
    "                \"feature_names\": X_train.columns.tolist(),\n",
    "                \"class_distribution_train\": y_train.value_counts().to_dict(),\n",
    "                \"class_distribution_test\": y_test.value_counts().to_dict(),\n",
    "            }\n",
    "            \n",
    "            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°\n",
    "            mlflow.log_params({\n",
    "                k: v for k, v in dataset_params.items()\n",
    "                if k not in [\"feature_names\", \"class_distribution_train\", \"class_distribution_test\"]\n",
    "            })\n",
    "            \n",
    "            # ç‰¹å¾´é‡åã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "            feature_path = Path(\"interim/features.json\")\n",
    "            feature_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            with open(feature_path, \"w\") as f:\n",
    "                json.dump(dataset_params[\"feature_names\"], f, indent=2)           \n",
    "            mlflow.log_artifact(str(feature_path), \"dataset_info\")\n",
    "            \n",
    "            # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚’è¨˜éŒ²\n",
    "            class_dist_path = Path(\"data/interim/class_distribution.json\")\n",
    "            with open(class_dist_path, \"w\") as f:\n",
    "                json.dump({\n",
    "                    \"train\": dataset_params[\"class_distribution_train\"],\n",
    "                    \"test\": dataset_params[\"class_distribution_test\"]\n",
    "                }, f, indent=2)\n",
    "            mlflow.log_artifact(str(class_dist_path), \"dataset_info\")        \n",
    "            \n",
    "            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¿½è·¡ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¨˜éŒ²ï¼‰\n",
    "            try:\n",
    "                mlflow.log_input(\n",
    "                    mlflow.data.from_pandas(            # type: ignore\n",
    "                        df,\n",
    "                        name=f\"citibike_data_{datetime.now().strftime('%Y%m%d')}\",\n",
    "                    ),\n",
    "                    context=\"training\",\n",
    "                )\n",
    "                logger.info(\"Dataset logged to MLflow\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to log dataset: {e}\")\n",
    "                \n",
    "            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ãƒ­ã‚°\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            logger.info(\"Training model...\")\n",
    "            model.fit(X_train, y_train)\n",
    "          \n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)          \n",
    "\n",
    "            # ç¢ºçŽ‡äºˆæ¸¬ãŒã‚ã‚‹å ´åˆã¯è¨˜éŒ²\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba_test = model.predict_proba(X_test)         \n",
    "            \n",
    "            metrics = {\n",
    "                # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹\n",
    "                \"test_accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "                \"test_precision\": precision_score(y_test, y_pred_test, zero_division=0),\n",
    "                \"test_recall\": recall_score(y_test, y_pred_test, zero_division=0),\n",
    "                \"test_f1_score\": f1_score(y_test, y_pred_test, zero_division=0),\n",
    "                # è¨“ç·´ã‚»ãƒƒãƒˆã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆéŽå­¦ç¿’ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰\n",
    "                \"train_accuracy\": accuracy_score(y_train, y_pred_train),\n",
    "                \"train_f1_score\": f1_score(y_train, y_pred_train, zero_division=0),\n",
    "            }\n",
    "            \n",
    "            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¸€æ‹¬ãƒ­ã‚°\n",
    "            mlflow.log_metrics(metrics)        \n",
    "            \n",
    "            logger.info(f\"Test Accuracy: {metrics['test_accuracy']:.4f}\")\n",
    "            logger.info(f\"Test F1-Score: {metrics['test_f1_score']:.4f}\")\n",
    "    \n",
    "            # æ··åŒè¡Œåˆ—ã‚’ä¿å­˜\n",
    "            cm = confusion_matrix(y_test, y_pred_test)\n",
    "            cm_path = Path(\"data/interim/confusion_matrix.json\")\n",
    "            cm_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            with open(cm_path, \"w\") as f:\n",
    "                json.dump({\n",
    "                    \"matrix\": cm.tolist(),\n",
    "                    \"labels\": [\"Non-Member\", \"Member\"]\n",
    "                }, f, indent=2)\n",
    "            mlflow.log_artifact(str(cm_path), \"evaluation\")\n",
    "            \n",
    "            # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n",
    "            signature = mlflow.models.infer_signature(      # type: ignore\n",
    "                X_train, \n",
    "                model.predict(X_train)\n",
    "            )\n",
    "\n",
    "            mlflow.sklearn.log_model(                       # type: ignore\n",
    "                model,\n",
    "                \"model\",\n",
    "                signature=signature,\n",
    "                input_example=X_train.iloc[:5],  # ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›ä¾‹\n",
    "            )\n",
    "            \n",
    "            mlflow.set_tags({\n",
    "                \"model_type\": model_name,\n",
    "                \"framework\": \"sklearn\",\n",
    "                \"dataset\": data_info,\n",
    "                \"best_metric\": \"f1_score\",\n",
    "            })\n",
    "            \n",
    "            logger.info(f\"Experiment logged successfully (run_id={run.info.run_id})\")\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during experiment: {str(e)}\")\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(status=\"FAILED\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8753131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading data from 2014-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: [PosixPath('/app/data/raw/2014-citibike-tripdata/1_January/201401-citibike-tripdata_1.csv')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Data split: train=240077, test=60020\n",
      "INFO:__main__:MLflow run started: 8aa5540182694226bf33ec993eee90e7\n",
      "ERROR:__main__:Error during experiment: [Errno 13] Permission denied: '/mlflow'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run logistic_regression_20251022_000522 at: http://mlflow:5000/#/experiments/1/runs/8aa5540182694226bf33ec993eee90e7\n",
      "ðŸ§ª View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m metrics = \u001b[43mtrain_and_log_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2014\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogistic_regression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_iter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msolver\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlbfgs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrandom_state\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mtrain_and_log_experiment\u001b[39m\u001b[34m(data_info, model_name, params, test_size, random_state, experiment_name)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(feature_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     85\u001b[39m     json.dump(dataset_params[\u001b[33m\"\u001b[39m\u001b[33mfeature_names\u001b[39m\u001b[33m\"\u001b[39m], f, indent=\u001b[32m2\u001b[39m)           \n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset_info\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚’è¨˜éŒ²\u001b[39;00m\n\u001b[32m     89\u001b[39m class_dist_path = Path(\u001b[33m\"\u001b[39m\u001b[33mdata/interim/class_distribution.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/mlflow/tracking/fluent.py:1445\u001b[39m, in \u001b[36mlog_artifact\u001b[39m\u001b[34m(local_path, artifact_path, run_id)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1416\u001b[39m \u001b[33;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[32m   1417\u001b[39m \u001b[33;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1442\u001b[39m \u001b[33;03m            mlflow.log_artifact(path)\u001b[39;00m\n\u001b[32m   1443\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1444\u001b[39m run_id = run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run().info.run_id\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/mlflow/tracking/client.py:2533\u001b[39m, in \u001b[36mMlflowClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m   2529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id.startswith(TRACE_REQUEST_ID_PREFIX):\n\u001b[32m   2530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   2531\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2532\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2533\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:675\u001b[39m, in \u001b[36mTrackingServiceClient.log_artifact\u001b[39m\u001b[34m(self, run_id, local_path, artifact_path)\u001b[39m\n\u001b[32m    673\u001b[39m     artifact_repo.log_artifacts(local_path, path_name)\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     \u001b[43martifact_repo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/mlflow/store/artifact/local_artifact_repo.py:46\u001b[39m, in \u001b[36mLocalArtifactRepository.log_artifact\u001b[39m\u001b[34m(self, local_file, artifact_path)\u001b[39m\n\u001b[32m     42\u001b[39m artifact_dir = (\n\u001b[32m     43\u001b[39m     os.path.join(\u001b[38;5;28mself\u001b[39m.artifact_dir, artifact_path) \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.artifact_dir\n\u001b[32m     44\u001b[39m )\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(artifact_dir):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     48\u001b[39m     shutil.copy2(local_file, os.path.join(artifact_dir, os.path.basename(local_file)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/mlflow/utils/file_utils.py:209\u001b[39m, in \u001b[36mmkdir\u001b[39m\u001b[34m(root, name)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno != errno.EEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(target):\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/mlflow/utils/file_utils.py:206\u001b[39m, in \u001b[36mmkdir\u001b[39m\u001b[34m(root, name)\u001b[39m\n\u001b[32m    204\u001b[39m target = os.path.join(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno != errno.EEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(target):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "    \u001b[31m[... skipping similar frames: makedirs at line 215 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/mlflow'"
     ]
    }
   ],
   "source": [
    "metrics = train_and_log_experiment(\n",
    "    data_info=[2014, 1],\n",
    "    model_name=\"logistic_regression\",\n",
    "    params={\n",
    "        \"max_iter\": 1000,\n",
    "        \"C\": 1.0,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5b42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
